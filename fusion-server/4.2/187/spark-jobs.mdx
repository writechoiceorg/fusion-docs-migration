---
title: "Spark Jobs"
permalink: "187"
---

Apache Spark can power a wide variety of data analysis jobs. In Fusion, Spark jobs are especially useful for generating [recommendations](/fusion-ai/4.2/482/recommendations-and-boosting).

## Spark job subtypes

For the Spark [job type](/fusion-server/4.2/184/jobs-overview#job-types), the available subtypes are listed below.

* [Aggregation](/fusion-server/4.2/388/aggregation-jobs)

  Define an aggregation job.
* [Custom Spark job](/fusion-server/4.2/383/custom-spark-jobs)

  Run a custom Spark job.
* [Script](/fusion-server/4.2/386/script-jobs)

  Run a custom Scala script as a Fusion job.

<Note>
[Additional Spark jobs](/fusion-ai/4.2/572/jobs-configuration) are available with a [Fusion AI](/fusion-ai/4.2/428/fusion-ai) license.
</Note>

## Spark job configuration

Spark jobs can be created and modified using the [Fusion UI](/fusion-server/4.2/184/jobs-overview#jobs-manager) or the [Spark Jobs API](/fusion-server/4.2/312/spark-jobs-api). They can be scheduled using the Fusion UI or the [Jobs API](/fusion-server/4.2/312/spark-jobs-api).

For the complete list of configuration parameters for all Spark job subtypes, see the [Jobs Configuration Reference](/fusion-server/4.2/184/jobs).