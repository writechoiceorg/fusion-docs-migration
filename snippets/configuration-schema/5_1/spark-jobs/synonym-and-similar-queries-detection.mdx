export const schema = {
  "additionalProperties": true,
  "category": "Other",
  "categoryPriority": 1,
  "description": "Use this job to generate synonym and similar query pairs.",
  "properties": {
    "analyzerConfigQuery": {
      "default": "{ \"analyzers\": [ { \"name\": \"LetterTokLowerStem\",\"charFilters\": [ { \"type\": \"htmlstrip\" } ],\"tokenizer\": { \"type\": \"letter\" },\"filters\": [{ \"type\": \"lowercase\" },{ \"type\": \"length\", \"min\": \"2\", \"max\": \"32767\" },{ \"type\": \"KStem\" }] }],\"fields\": [{ \"regex\": \".+\", \"analyzer\": \"LetterTokLowerStem\" } ]}",
      "description": "LuceneTextAnalyzer schema for tokenizing queries (JSON-encoded)",
      "hints": [
        "lengthy",
        "advanced",
        "code/json"
      ],
      "minLength": 1,
      "title": "Lucene Analyzer Schema",
      "type": "string"
    },
    "countField": {
      "default": "aggr_count_i",
      "description": "Solr field containing number of events (e.g., number of clicks). Change to count_i when running against raw signals",
      "title": "Event Count Field Name",
      "type": "string"
    },
    "dataFormat": {
      "default": "solr",
      "description": "Spark-compatible format which training data comes in (like 'solr', 'hdfs', 'file', 'parquet' etc)",
      "enum": [
        "solr",
        "hdfs",
        "file",
        "parquet"
      ],
      "hints": [
        "advanced"
      ],
      "title": "Data format",
      "type": "string"
    },
    "docIdField": {
      "default": "doc_id_s ",
      "description": "Solr field containing document id that user clicked. Change to doc_id for raw signal collection",
      "title": "Document id Field Name",
      "type": "string"
    },
    "enableAutoPublish": {
      "default": false,
      "description": "If true, automatically publishes rewrites for rules. Default is false to allow for initial human-aided reviewing",
      "hints": [
        "advanced"
      ],
      "title": "Enable auto-publishing",
      "type": "boolean"
    },
    "fieldToVectorize": {
      "default": "query_s",
      "description": "Field containing queries. Change to query to use against raw signals",
      "minLength": 1,
      "title": "Query Field Name",
      "type": "string"
    },
    "id": {
      "description": "The ID for this Spark job. Used in the API to reference this job. Allowed characters: a-z, A-Z, dash (-) and underscore (_). Maximum length: 63 characters.",
      "maxLength": 63,
      "pattern": "[a-zA-Z][_\\-a-zA-Z0-9]*[a-zA-Z0-9]?",
      "title": "Spark Job ID",
      "type": "string"
    },
    "keyPhraseCollection": {
      "description": "Solr collection containing reviewed result of Phrase extraction job. Defaults to the query_rewrite_staging collection for the app.",
      "title": "Phrase Extraction Job Result Collection",
      "type": "string"
    },
    "keyPhraseFilterQuery": {
      "default": "type:phrase",
      "description": "Solr query to additionally filter the phrase extraction results. Defaults to reading all approved phrases.",
      "title": "Phrase Extraction Job Result Filter Query",
      "type": "string"
    },
    "keywordsBlobName": {
      "blobType": "file:spark",
      "description": "Name of the keywords blob resource. Typically, this should be a csv file uploaded to blob store in a specific format. Check documentation for more details on format and uploading to blob store.",
      "reference": "blob",
      "title": "Keywords Blob Store",
      "type": "string"
    },
    "minQueryCount": {
      "default": 5,
      "description": "The min number of clicked documents needed for comparing queries.",
      "hints": [
        "advanced"
      ],
      "title": "Query Clicks Threshold",
      "type": "integer"
    },
    "misspellingCollection": {
      "description": "Solr collection containing reviewed result of Token and phrase spell correction job. Defaults to the query_rewrite_staging collection for the app.",
      "title": "Misspelling Job Result Collection",
      "type": "string"
    },
    "misspellingsFilterQuery": {
      "default": "type:spell",
      "description": "Solr query to additionally filter the misspelling results. Defaults to reading all approved spell corrections.",
      "title": "Misspelling Job Result Filter Query",
      "type": "string"
    },
    "outputCollection": {
      "description": "Collection to store synonym and similar query pairs.",
      "hints": [
        "dummy"
      ],
      "title": "Output Collection",
      "type": "string"
    },
    "overlapThreshold": {
      "default": 0.5,
      "description": "The threshold above which query pairs are consider similar. We can get more synonym pairs if increase this value but quality may get reduced.",
      "hints": [
        "advanced"
      ],
      "title": "Query Similarity Threshold",
      "type": "number"
    },
    "overwriteOutput": {
      "default": true,
      "description": "Overwrite output collection",
      "hints": [
        "hidden",
        "advanced"
      ],
      "title": "Overwrite Output",
      "type": "boolean"
    },
    "randomSeed": {
      "default": 1234,
      "description": "For any deterministic pseudorandom number generation",
      "hints": [
        "advanced"
      ],
      "title": "Random seed",
      "type": "integer"
    },
    "similarityThreshold": {
      "default": 0.01,
      "description": "The threshold above which synonym pairs are consider similar. We can get more synonym pairs if increase this value but quality may get reduced.",
      "hints": [
        "advanced"
      ],
      "title": "Synonym Similarity Threshold",
      "type": "number"
    },
    "sourceFields": {
      "description": "Solr fields to load (comma-delimited). Leave empty to allow the job to select the required fields to load at runtime.",
      "hints": [
        "hidden"
      ],
      "title": "Fields to Load",
      "type": "string"
    },
    "sparkConfig": {
      "description": "Spark configuration settings.",
      "hints": [
        "advanced"
      ],
      "items": {
        "properties": {
          "key": {
            "title": "Parameter Name",
            "type": "string"
          },
          "value": {
            "title": "Parameter Value",
            "type": "string"
          }
        },
        "required": [
          "key"
        ],
        "type": "object"
      },
      "title": "Spark Settings",
      "type": "array"
    },
    "stopwordsList": {
      "description": "Stopwords defined in Lucene analyzer config",
      "hints": [
        "readonly",
        "hidden"
      ],
      "items": {
        "blobType": "file:spark",
        "minLength": 1,
        "reference": "blob",
        "type": "string"
      },
      "title": "List of stopwords",
      "type": "array"
    },
    "synonymBlobName": {
      "blobType": "file:spark",
      "description": "Name of the custom synonym blob resource. This is a Solr synonym file that will be used in the synonym detection job and will override any generated synonyms (indicated by a 'supplied' field in the Rules UI).",
      "hints": [
        "advanced"
      ],
      "reference": "blob",
      "title": "Custom Synonym Blob Store",
      "type": "string"
    },
    "trainingCollection": {
      "description": "Collection containing queries, document id and event counts. Can be either signal aggregation collection or raw signals collection.",
      "minLength": 1,
      "title": "Input Collection",
      "type": "string"
    },
    "trainingDataFilterQuery": {
      "default": "*:*",
      "description": "Solr query to additionally filter the input collection.",
      "hints": [
        "dummy"
      ],
      "minLength": 3,
      "title": "Data filter query",
      "type": "string"
    },
    "trainingDataFrameConfigOptions": {
      "additionalProperties": {
        "type": "string"
      },
      "description": "Additional spark dataframe loading configuration options",
      "hints": [
        "advanced"
      ],
      "properties": {},
      "title": "Dataframe Config Options",
      "type": "object"
    },
    "trainingDataSamplingFraction": {
      "default": 1,
      "description": "Fraction of the training data to use",
      "exclusiveMaximum": false,
      "hints": [
        "advanced"
      ],
      "maximum": 1,
      "title": "Training data sampling fraction",
      "type": "number"
    },
    "type": {
      "default": "synonymDetection",
      "enum": [
        "synonymDetection"
      ],
      "hints": [
        "readonly"
      ],
      "title": "Spark Job Type",
      "type": "string"
    },
    "writeOptions": {
      "description": "Options used when writing output to Solr.",
      "hints": [
        "advanced"
      ],
      "items": {
        "properties": {
          "key": {
            "title": "Parameter Name",
            "type": "string"
          },
          "value": {
            "title": "Parameter Value",
            "type": "string"
          }
        },
        "required": [
          "key"
        ],
        "type": "object"
      },
      "title": "Write Options",
      "type": "array"
    }
  },
  "propertyGroups": [
    {
      "label": "Input/Output Parameters",
      "properties": [
        "trainingCollection",
        "outputCollection",
        "dataFormat",
        "trainingDataFilterQuery",
        "writeOptions",
        "trainingDataFrameConfigOptions",
        "trainingDataSamplingFraction",
        "randomSeed"
      ]
    },
    {
      "label": "Field Parameters",
      "properties": [
        "fieldToVectorize",
        "sourceFields",
        "countField"
      ]
    },
    {
      "label": "Model Tuning Parameters",
      "properties": [
        "overlapThreshold"
      ]
    },
    {
      "label": "Featurization Parameters",
      "properties": [
        "analyzerConfigQuery"
      ]
    },
    {
      "label": "Misc. Parameters",
      "properties": [
        "keywordsBlobName"
      ]
    }
  ],
  "required": [
    "id",
    "trainingCollection",
    "fieldToVectorize",
    "countField",
    "docIdField",
    "type"
  ],
  "title": "Synonym and Similar Queries Detection",
  "type": "object"
}
