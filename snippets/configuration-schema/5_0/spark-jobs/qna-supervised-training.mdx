export const schema = {
  "type": "object",
  "title": "QnA Supervised Training",
  "description": "Trains QnA model on a supervised basis with with pre-trained or trained embeddings and deploys the trained model to the ML Model Service",
  "required": [
    "id",
    "trainingCollection",
    "questionColName",
    "answerColName",
    "deployModelName",
    "type"
  ],
  "properties": {
    "id": {
      "type": "string",
      "title": "Job ID",
      "description": "The ID for this job. Used in the API to reference this job. Allowed characters: a-z, A-Z, dash (-) and underscore (_)",
      "maxLength": 63,
      "pattern": "^[A-Za-z0-9_\\-]+$"
    },
    "sparkConfig": {
      "type": "array",
      "title": "Additional parameters",
      "description": "Provide additional key/value pairs to be injected into the training JSON map at runtime. Values will be inserted as-is, so use \" to surround string values",
      "hints": [
        "advanced"
      ],
      "items": {
        "type": "object",
        "required": [
          "key"
        ],
        "properties": {
          "key": {
            "type": "string",
            "title": "Parameter Name"
          },
          "value": {
            "type": "string",
            "title": "Parameter Value"
          }
        }
      }
    },
    "useAutoML": {
      "type": "boolean",
      "title": "Perform auto hyperparameter tuning",
      "description": "Automatically tune hyperparameters (will take longer to train)",
      "default": false
    },
    "trainingCollection": {
      "type": "string",
      "title": "Training Collection",
      "description": "Solr Collection containing question and answer pairs",
      "minLength": 1
    },
    "questionColName": {
      "type": "string",
      "title": "Question Field",
      "description": "Name of the field containing questions",
      "minLength": 1
    },
    "answerColName": {
      "type": "string",
      "title": "Answer Field",
      "description": "Name of the field containing answers",
      "minLength": 1
    },
    "deployModelName": {
      "type": "string",
      "title": "Model Deployment Name",
      "description": "Name of the model to be used for deployment (must be a valid DNS subdomain with no underscores)",
      "maxLength": 30,
      "pattern": "^[A-Za-z0-9_\\-]+$"
    },
    "testMode": {
      "type": "boolean",
      "title": "Test Mode",
      "description": "If set to true, then the training will exit after the first iteration. Useful for ensuring that the end-to-end pipeline is working",
      "default": false,
      "hints": [
        "hidden"
      ]
    },
    "modelReplicas": {
      "type": "integer",
      "title": "Model replicas",
      "description": "How many replicas of the model should be deployed by Seldon Core",
      "default": 1
    },
    "cudnn": {
      "type": "boolean",
      "title": "GPU available",
      "description": "Use GPU for training if available (recommended NVIDIA GPU with 8Gb or more memory)",
      "default": false,
      "hints": [
        "advanced"
      ]
    },
    "useCustomEmbeddings": {
      "type": "boolean",
      "title": "Use custom embeddings",
      "description": "Choose this option when there are many uncommon words or jargons in data. NOTE: please look at log for warning about percentage of covered vocabulary words, if this proportion is less than 80%, please set this parameter to true and do not use the pre-trained embeddings shipped with our package",
      "default": false
    },
    "samplingProportion": {
      "type": "number",
      "title": "Sampling proportion",
      "description": "The proportion of data to be sampled from the full dataset. Use a value between 0 and 1 for a proportion (e.g. 0.5 for 50%), or for a specific number of examples, use an integer larger than 1. Leave blank for no sampling",
      "hints": [
        "advanced"
      ]
    },
    "seed": {
      "type": "integer",
      "title": "Seed",
      "description": "The proportion of data to be sampled from the full dataset. Use a value between 0 and 1 for a proportion (e.g. 0.5 for 50%), or for a specific number of examples, use an integer larger than 1",
      "default": 12345,
      "hints": [
        "hidden"
      ]
    },
    "minTokensNum": {
      "type": "integer",
      "title": "Minimum number of words in doc",
      "description": "Drop document if the total words is lower than this value",
      "default": 1,
      "hints": [
        "advanced"
      ],
      "minimum": 1,
      "exclusiveMinimum": false
    },
    "maxTokensNum": {
      "type": "integer",
      "title": "Maximum number of words in doc",
      "description": "Drop document if the total words is greater than this value",
      "default": 5000,
      "hints": [
        "advanced"
      ],
      "minimum": 1,
      "exclusiveMinimum": false
    },
    "lowerCases": {
      "type": "boolean",
      "title": "Lower case all words",
      "description": "Whether to lower case all words in training, i.e. whether to treat upper case and lower case words equally.",
      "default": false,
      "hints": [
        "advanced"
      ]
    },
    "maxVocabSize": {
      "type": "integer",
      "title": "Maximum vocabulary size",
      "description": "Maximum number of words in vocabulary, words will be trimmed if frequency is too low",
      "default": 100000,
      "hints": [
        "advanced"
      ],
      "minimum": 1,
      "exclusiveMinimum": false
    },
    "w2vEpochs": {
      "type": "integer",
      "title": "Word2Vec training epochs",
      "description": "Number of epochs to train custom word2vec embeddings",
      "default": 15,
      "hints": [
        "advanced"
      ]
    },
    "w2vTextsCollection": {
      "type": "string",
      "title": "Word2Vec training collection",
      "description": "Name of the collection which contains the documents that will be used to train Word2Vec if pre-trained word2vec embeddings won't be used."
    },
    "w2vTextColumns": {
      "type": "string",
      "title": "Word2Vec training fields",
      "description": "Which fields in the Word2Vec training collection to use in Word2Vec vocabulary embedding training. If multiple fields, please separate them by comma, e.g. description_t,title_t."
    },
    "w2vVectorSize": {
      "type": "integer",
      "title": "Size of word vectors",
      "description": "Word-vector dimensionality to represent text (suggested dimension ranges: 100~150",
      "default": 150,
      "hints": [
        "advanced"
      ]
    },
    "w2vWindowSize": {
      "type": "integer",
      "title": "Word2Vec window size",
      "description": "The window size (context words from [-window, window]) for Word2Vec",
      "default": 8,
      "hints": [
        "advanced"
      ]
    },
    "valSize": {
      "type": "number",
      "title": "Validation sample size",
      "description": "Proportion of the original data to be used as validation sample",
      "default": 0.1,
      "hints": [
        "advanced"
      ],
      "minimum": 0.001,
      "exclusiveMinimum": false
    },
    "numPos": {
      "type": "integer",
      "title": "Number of positive QA pairs",
      "description": "Number of answers to be used for each question when constructing validation data",
      "default": 5,
      "hints": [
        "advanced"
      ]
    },
    "numNeg": {
      "type": "integer",
      "title": " Number of negative QA pairs",
      "description": "Number of non-matching answers randomly sampled for each question to be used as negative examples when constructing",
      "default": 15,
      "hints": [
        "advanced"
      ]
    },
    "qMaxLen": {
      "type": "integer",
      "title": "Question length",
      "description": "Average length of question by number of tokens"
    },
    "aMaxLen": {
      "type": "integer",
      "title": "Answer length",
      "description": "Average length of question by number of tokens"
    },
    "embSPDP": {
      "type": "number",
      "title": "Dropout ratio",
      "description": "Fraction of input to drop with Dropout layer (from 0-1)",
      "default": 0.15,
      "hints": [
        "advanced"
      ]
    },
    "trainBatch": {
      "type": "integer",
      "title": "Training batch size",
      "description": "Batch size during training. If left blank, this will be set automatically based on the input data"
    },
    "infBatch": {
      "type": "integer",
      "title": "Inference batch size used in validation",
      "description": "Batch size during validation. If left blank, this will be set automatically based on the input data"
    },
    "rnnNamesList": {
      "type": "string",
      "title": "RNN function list",
      "description": "List of layers of RNNs can be used, with possible values of lstm, gru. E.g. [\"lstm\", \"lstm\"]. This value will be automatically decided based on data if left blank"
    },
    "rnnUnitsList": {
      "type": "string",
      "title": "RNN function units list",
      "description": "List of RNN layer units numbers, corresponding to RNN function list. E.g. 150, 150. This value will be automatically decided based on data if left blank"
    },
    "epochs": {
      "type": "integer",
      "title": "Number of epochs to be used in training"
    },
    "weightDecay": {
      "type": "number",
      "title": "Weight decay",
      "description": "L2 penalty used in Adam optimization. Bigger values will provide stronger regularization",
      "default": 0.0001,
      "hints": [
        "advanced"
      ]
    },
    "monitorPatience": {
      "type": "integer",
      "title": "Monitor patience",
      "description": "Stop training if no improvement in metrics by this number of epochs"
    },
    "baseLR": {
      "type": "number",
      "title": "Base learning rate",
      "description": "Base learning rate used in cyclical training"
    },
    "maxLR": {
      "type": "number",
      "title": "Maximum learning rate",
      "description": "Maximum learning rate used in cyclical training"
    },
    "extraTrainingArgs": {
      "type": "string",
      "title": "Extra training args for Python scripts",
      "description": "Add any additional arguments for the Python training scripts in this field",
      "hints": [
        "advanced"
      ]
    },
    "monitorMetric": {
      "type": "string",
      "title": "Monitor metric",
      "description": "The metric that is chosen among all possible metrics at k to be used to decide when to stop training",
      "default": "mrr@3",
      "hints": [
        "advanced"
      ]
    },
    "monitorMetricsList": {
      "type": "string",
      "title": "Metrics list",
      "description": "List of evaluation metrics on validation data that will be printed in the log at the end of each epoch",
      "default": "[\"map\", \"mrr\", \"precision\", \"recall\", \"roc_auc\"]",
      "hints": [
        "advanced"
      ]
    },
    "kList": {
      "type": "string",
      "title": "Metrics@k list",
      "description": "The k retrieval position that will be used to compute for each metric",
      "default": "[1,3,5]",
      "hints": [
        "advanced"
      ]
    },
    "numClusters": {
      "type": "integer",
      "title": "Number of clusters",
      "description": "Number of clusters to be used for fast dense vector retrieval. Note no clustering will be applied if this is set to 0. If left blank, cluster count will be inferred by the job depending on the data",
      "hints": [
        "advanced"
      ]
    },
    "topKClusters": {
      "type": "integer",
      "title": "Top k of clusters to return",
      "description": "How many closest clusters the model can find for each query. At retrieval time, all answers in top k nearest clusters will be returned and reranked",
      "default": 10,
      "hints": [
        "advanced"
      ]
    },
    "unidecode": {
      "type": "boolean",
      "title": "Apply unicode decoding",
      "description": "Use Unidecode library to transform Unicode input into ASCII transliterations",
      "default": true,
      "hints": [
        "hidden"
      ]
    },
    "scaleOnly": {
      "type": "boolean",
      "title": "Scale Seldon Core Replica Deployment Only",
      "description": "Run job but only adjust Seldon Core replica count (no training)",
      "default": false,
      "hints": [
        "hidden"
      ]
    },
    "type": {
      "type": "string",
      "title": "Spark Job Type",
      "enum": [
        "argo-qna-supervised"
      ],
      "default": "argo-qna-supervised",
      "hints": [
        "readonly"
      ]
    }
  },
  "additionalProperties": true,
  "category": "Other",
  "categoryPriority": 1,
  "propertyGroups": [
    {
      "label": "Input/Output Parameters",
      "properties": [
        "trainingCollection",
        "questionColName",
        "answerColName",
        "deployModelName",
        "modelReplicas",
        "testMode",
        "seed",
        "valSize"
      ]
    },
    {
      "label": "Data Preprocessing",
      "properties": [
        "samplingProportion",
        "minTokensNum",
        "maxTokensNum",
        "lowerCases",
        "unidecode",
        "maxVocabSize"
      ]
    },
    {
      "label": "Word2Vec Initialization",
      "properties": [
        "useCustomEmbeddings",
        "withTexts",
        "w2vTextsCollection",
        "w2vTextColumns",
        "w2vEpochs",
        "w2vVectorSize",
        "w2vWindowSize",
        "w2vSamplingProportion"
      ]
    },
    {
      "label": "Model Tuning Parameters",
      "properties": [
        "cudnn",
        "numPos",
        "numNeg",
        "qMaxLen",
        "aMaxLen",
        "kList",
        "monitorMetricsList",
        "monitorMetric",
        "numClusters",
        "topKClusters"
      ]
    },
    {
      "label": "Model Tuning Parameters (used with no auto-hyperparameter tuning)",
      "properties": [
        "extraTrainingArgs",
        "embSPDP",
        "infBatch",
        "trainBatch",
        "rnnNamesList",
        "rnnUnitsList",
        "epochs",
        "weightDecay",
        "monitorPatience",
        "baseLR",
        "maxLR"
      ]
    }
  ]
}
