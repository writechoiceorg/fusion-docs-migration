export const schema = {
  "type": "object",
  "title": "Query-to-Query Similarity",
  "description": "Use this job to to batch compute query-query similarities using a co-occurrence based approach",
  "required": [
    "id",
    "trainingCollection",
    "fieldToVectorize",
    "docIdField",
    "type"
  ],
  "properties": {
    "id": {
      "type": "string",
      "title": "Spark Job ID",
      "description": "The ID for this Spark job. Used in the API to reference this job. Allowed characters: a-z, A-Z, dash (-) and underscore (_). Maximum length: 63 characters.",
      "maxLength": 63,
      "pattern": "^[A-Za-z0-9_\\-]+$"
    },
    "sparkConfig": {
      "type": "array",
      "title": "Spark Settings",
      "description": "Spark configuration settings.",
      "hints": [
        "advanced"
      ],
      "items": {
        "type": "object",
        "required": [
          "key"
        ],
        "properties": {
          "key": {
            "type": "string",
            "title": "Parameter Name"
          },
          "value": {
            "type": "string",
            "title": "Parameter Value"
          }
        }
      }
    },
    "trainingCollection": {
      "type": "string",
      "title": "Input Collection",
      "description": "Collection containing queries, document id and event counts. Can be either signal aggregation collection or raw signals collection."
    },
    "fieldToVectorize": {
      "type": "string",
      "title": "Query Field Name",
      "description": "Field containing queries.",
      "default": "query_s",
      "minLength": 1
    },
    "dataFormat": {
      "type": "string",
      "title": "Data format",
      "description": "Spark-compatible format which training data comes in (like 'solr', 'hdfs', 'file', 'parquet' etc)",
      "enum": [
        "solr",
        "hdfs",
        "file",
        "parquet"
      ],
      "default": "solr",
      "hints": [
        "advanced"
      ]
    },
    "trainingDataFrameConfigOptions": {
      "type": "object",
      "title": "Dataframe Config Options",
      "description": "Additional spark dataframe loading configuration options",
      "properties": {},
      "additionalProperties": {
        "type": "string"
      },
      "hints": [
        "advanced"
      ]
    },
    "trainingDataFilterQuery": {
      "type": "string",
      "title": "Data filter query",
      "description": "Solr query to additionally filter the input collection.",
      "default": "*:*",
      "hints": [
        "dummy"
      ],
      "minLength": 3
    },
    "trainingDataSamplingFraction": {
      "type": "number",
      "title": "Training data sampling fraction",
      "description": "Fraction of the training data to use",
      "default": 1,
      "hints": [
        "advanced"
      ],
      "maximum": 1,
      "exclusiveMaximum": false
    },
    "randomSeed": {
      "type": "integer",
      "title": "Random seed",
      "description": "For any deterministic pseudorandom number generation",
      "default": 1234,
      "hints": [
        "advanced"
      ]
    },
    "outputCollection": {
      "type": "string",
      "title": "Output collection",
      "description": "Collection to store synonym and similar query pairs.",
      "hints": [
        "dummy"
      ]
    },
    "overwriteOutput": {
      "type": "boolean",
      "title": "Overwrite Output",
      "description": "Overwrite output collection",
      "default": true,
      "hints": [
        "hidden",
        "advanced"
      ]
    },
    "sourceFields": {
      "type": "string",
      "title": "Fields to Load",
      "description": "Solr fields to load (comma-delimited). Leave empty to allow the job to select the required fields to load at runtime.",
      "hints": [
        "dummy",
        "hidden"
      ]
    },
    "specialCharsFilterString": {
      "type": "string",
      "title": "Special characters to be filtered out",
      "description": "String of special characters to be filtered from queries.",
      "default": "~!@#$^%&*\\(\\)_+={}\\[\\]|;:\"'<,>.?`/\\\\-",
      "hints": [
        "advanced"
      ]
    },
    "minQueryLength": {
      "type": "integer",
      "title": "Minimum query length",
      "description": "Queries below this length (in number of characters) will not be considered for generating recommendations.",
      "default": 3,
      "minimum": 1,
      "exclusiveMinimum": false
    },
    "maxQueryLength": {
      "type": "integer",
      "title": "Maximum query length",
      "description": "Queries above this length will not be considered for generating recommendations.",
      "default": 50,
      "minimum": 1,
      "exclusiveMinimum": false
    },
    "countField": {
      "type": "string",
      "title": "Event Count Field Name",
      "description": "Solr field containing number of events (e.g., number of clicks).",
      "default": "count_i"
    },
    "docIdField": {
      "type": "string",
      "title": "Document id Field Name",
      "description": "Solr field containing document id that user clicked.",
      "default": "doc_id_s"
    },
    "overlapThreshold": {
      "type": "number",
      "title": "Query Similarity Threshold",
      "description": "The threshold above which query pairs are consider similar. Decreasing the value can fetch more pairs at the expense of quality.",
      "default": 0.3,
      "hints": [
        "advanced"
      ],
      "maximum": 1,
      "exclusiveMaximum": false
    },
    "minQueryCount": {
      "type": "integer",
      "title": "Query Clicks Threshold",
      "description": "The minimum number of clicked documents needed for comparing queries.",
      "default": 1,
      "hints": [
        "advanced"
      ],
      "minimum": 1,
      "exclusiveMinimum": false
    },
    "overlapEnabled": {
      "type": "boolean",
      "title": "Boost on token overlap",
      "description": "Maximize score for query pairs with overlapping tokens by setting score to 1.",
      "default": true,
      "hints": [
        "advanced"
      ]
    },
    "tokenOverlapValue": {
      "type": "number",
      "title": "Minimum match for token overlap",
      "description": "Minimum amount of overlap to consider for boosting. To specify overlap in terms of ratio, specify a value in (0, 1). To specify overlap in terms of exact count, specify a value >= 1. If value is 0, boost will be applied if one query is a substring of its pair.Stopwords are ignored while counting overlaps.",
      "default": 1,
      "hints": [
        "advanced"
      ]
    },
    "sessionIdField": {
      "type": "string",
      "title": "Session/User ID field",
      "description": "If session id is not available, specify user id field instead. If this field is left blank, session based recommendations will be disabled.",
      "default": "session_id_s"
    },
    "minPairOccCount": {
      "type": "integer",
      "title": "Minimum query-recommendation pair occurrence count",
      "description": "Minimum number of times a query pair must be generated to be considered valid.",
      "default": 2,
      "hints": [
        "advanced"
      ],
      "minimum": 1,
      "exclusiveMinimum": false
    },
    "stopwordsBlobName": {
      "type": "string",
      "title": "Stopwords Blob Store",
      "description": "Name of the stopwords blob resource. This is a .txt file with one stopword per line. By default the file is called stopwords/stopwords_nltk_en.txt however a custom file can also be used. Check documentation for more details on format and uploading to blob store.",
      "default": "stopwords/stopwords_nltk_en.txt",
      "reference": "blob",
      "blobType": "file:spark"
    },
    "writeOptions": {
      "type": "array",
      "title": "Write Options",
      "description": "Options used when writing output to Solr.",
      "hints": [
        "advanced"
      ],
      "items": {
        "type": "object",
        "required": [
          "key"
        ],
        "properties": {
          "key": {
            "type": "string",
            "title": "Parameter Name"
          },
          "value": {
            "type": "string",
            "title": "Parameter Value"
          }
        }
      }
    },
    "type": {
      "type": "string",
      "title": "Spark Job Type",
      "enum": [
        "similar_queries"
      ],
      "default": "similar_queries",
      "hints": [
        "readonly"
      ]
    }
  },
  "additionalProperties": true,
  "category": "Other",
  "categoryPriority": 1,
  "propertyGroups": [
    {
      "label": "Input/Output Parameters",
      "properties": [
        "trainingCollection",
        "outputCollection",
        "dataFormat",
        "trainingDataFilterQuery",
        "trainingDataFrameConfigOptions",
        "trainingDataSamplingFraction",
        "randomSeed",
        "writeOptions"
      ]
    },
    {
      "label": "Field Parameters",
      "properties": [
        "fieldToVectorize",
        "sourceFields",
        "countField",
        "docIdField",
        "sessionIdField"
      ]
    },
    {
      "label": "Model Tuning Parameters",
      "properties": [
        "minQueryLength",
        "maxQueryLength",
        "specialCharsFilterString",
        "stopwordsBlobName",
        "overlapThreshold",
        "overlapEnabled",
        "tokenOverlapValue",
        "minQueryCount",
        "minPairOccCount"
      ]
    }
  ]
}
