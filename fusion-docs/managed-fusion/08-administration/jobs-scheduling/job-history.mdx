---
title: "Job history"
permalink: "hnuexi"
---

import {InlineImage} from "/snippets/InlineImage.mdx";

## Checking a job status

### With the API

You can see the current job states of all datasources for the app `myApp` by calling the Jobs API:

```sh
curl -u USERNAME:PASSWORD http://proxy-url:6764/api/apps/myApp/jobs?type=datasource
```

If a job has never run, a Jobs API call returns the following:

```json
[
  {
    "resource": "datasource:myDatasource",
    "enabled": true,
    "startedBy": "09765f1d-2f1c-4c3b-ba22-887e3886d8aa",
    "status": "ready",
    "extra": {}
  }
]
```

<Note>
The value **`datasource:myDatasource`** indicates a datasource, **`myDatasource`**, is present. The line **`"status": "ready"`** indicates the current state of the job, which has never run.
</Note>

After a job successfully completes, the following is returned:

```json
[
  {
    "resource": "datasource:myDatasource",
    "enabled": true,
    "startedBy": "09765f1d-2f1c-4c3b-ba22-887e3886d8aa",
    "status": "success",
    "extra": {
      "counter.failed": 0,
      "counter.other.pipeline.in": 58242,
      "counter.stage.field-mapping::d3ebd921-6065-479e-9d45-0bfed819346b.processed": 58241,
      "counter.deleted": 0,
      "counter.stage.solr-dynamic-field-name-mapping::e6aa9c51-2867-40a0-97fd-34d909098a20.processed": 58241,
      "counter.new": 2268,
      "counter.output": 58241,
      "counter.other.pipeline.complete": 58242,
      "datasourceId": "myDatasource",
      "counter.input": 60435,
      "startTime": 1586298855843,
      "endTime": 1586299313433,
      "counter.skipped": 2194,
      "counter.stage.solr-index::01e1c561-0440-44b2-afb4-d6ff471f646c.processed": 58241,
      "counter.other.pipeline.out": 58242
    },
    "lastStartTime": "2020-04-07T22:34:15.852Z",
    "lastEndTime": "2020-04-07T22:41:59.271Z"
  }
]
```

To see the complete job history, use the following Jobs API call:

```
curl -u USERNAME:PASSWORD http://proxy-url:6764/api/jobs/datasource:myDatasource/history
```

The following is returned:

```json
[
  {
    "resource": "datasource:myDatasource",
    "runId": "fXfKTQNSKM",
    "startTime": "2020-04-07T22:34:15.852Z",
    "endTime": "2020-04-07T22:41:59.271Z",
    "status": "success",
    "extra": {
      "counter.failed": 0,
      "counter.other.pipeline.in": 58242,
      "counter.stage.field-mapping::d3ebd921-6065-479e-9d45-0bfed819346b.processed": 58241,
      "counter.deleted": 0,
      "counter.stage.solr-dynamic-field-name-mapping::e6aa9c51-2867-40a0-97fd-34d909098a20.processed": 58241,
      "counter.new": 2268,
      "counter.output": 58241,
      "counter.other.pipeline.complete": 58242,
      "datasourceId": "myDatasource",
      "counter.input": 60435,
      "startTime": 1586298855843,
      "endTime": 1586299313433,
      "counter.skipped": 2194,
      "counter.stage.solr-index::01e1c561-0440-44b2-afb4-d6ff471f646c.processed": 58241,
      "counter.other.pipeline.out": 58242
    },
    "startedBy": "09765f1d-2f1c-4c3b-ba22-887e3886d8aa"
  },
  {
    "resource": "datasource:myDatasource",
    "runId": "XxrxochVOB",
    "startTime": "2020-04-07T20:06:25.819Z",
    "endTime": "2020-04-07T20:14:01.686Z",
    "status": "success",
    "extra": {
      "counter.failed": 0,
      "counter.other.pipeline.in": 59090,
      "counter.stage.field-mapping::d3ebd921-6065-479e-9d45-0bfed819346b.processed": 59089,
      "counter.deleted": 0,
      "counter.stage.solr-dynamic-field-name-mapping::e6aa9c51-2867-40a0-97fd-34d909098a20.processed": 59089,
      "counter.new": 2268,
      "counter.output": 59089,
      "counter.other.pipeline.complete": 59090,
      "datasourceId": "myDatasource",
      "counter.input": 61283,
      "startTime": 1586289985809,
      "endTime": 1586290440433,
      "counter.skipped": 2194,
      "counter.stage.solr-index::01e1c561-0440-44b2-afb4-d6ff471f646c.processed": 59089,
      "counter.other.pipeline.out": 59090
    },
    "startedBy": "09765f1d-2f1c-4c3b-ba22-887e3886d8aa"
  },
  {
    "resource": "datasource:myDatasource",
    "runId": "2jy3UemLTp",
    "startTime": "2020-04-07T19:23:39.576Z",
    "endTime": "2020-04-07T19:31:26.694Z",
    "status": "success",
    "extra": {
      "counter.failed": 0,
      "counter.other.pipeline.in": 58906,
      "counter.stage.field-mapping::d3ebd921-6065-479e-9d45-0bfed819346b.processed": 58905,
      "counter.deleted": 0,
      "counter.stage.solr-dynamic-field-name-mapping::e6aa9c51-2867-40a0-97fd-34d909098a20.processed": 58905,
      "counter.new": 2268,
      "counter.output": 58905,
      "counter.other.pipeline.complete": 58906,
      "datasourceId": "myDatasource",
      "counter.input": 61099,
      "startTime": 1586287419556,
      "endTime": 1586287883825,
      "counter.skipped": 2194,
      "counter.stage.solr-index::01e1c561-0440-44b2-afb4-d6ff471f646c.processed": 58905,
      "counter.other.pipeline.out": 58906
    },
    "startedBy": "09765f1d-2f1c-4c3b-ba22-887e3886d8aa"
  }
]
```

The section [How does the Jobs API work?](#how-it-works) below gives additional details on how the Jobs API retrieves information from Managed Fusion. See the [Jobs API reference](/managed-fusion/5.9/lggfzz/jobs-api) for more information.

#### Job history results field definitions

| Field | Definition |
| --- | --- |
| **counter.deleted** | Total number of documents deleted or removed from the Solr index. |
| **counter.failed** | Total number of documents not indexed due to failure. The errors are written to the log. |
| **counter.input** | Total number of fetched documents passed to the index pipeline. |
| **counter.new** | Total number of documents fetched for the first time. |
| **counter.output** | Total number of documents processed in the run (sum of failed + deleted + indexed documents). |
| **counter.skipped** | Total number of documents skipped due to rules such as max, min, and file size. |
| **endTime** | Time the job concluded, aborted, or was manually stopped. |
| **resource: datasource** | Name of the datasource. |
| **startTime** | Time the job started. |
| **status** | Job status such as Success, Running, or Aborted. |

### With the UI

In the Managed Fusion UI, navigate to **Indexing** > **Datasources**. Click a datasource to open the datasource panel.

<Frame>![Datasource panel](/assets/images/5.1/datasource-panel.png)</Frame>

Note that the **Last run start** and **Last run stop** values are equivalent to the `lastStartTime` and `lastEndTime` values from the Jobs API call. (These values are only present if a job has been run at least once.)

| Icon | Description |
| --- | --- |
| <InlineImage src="/assets/images/5.1/job-run-button-c.png" alt="Run button"/> | The **Run** button opens a panel containing various run options and information. |
| <InlineImage src="/assets/images/5.1/job-start-button-c.png" alt="Start button"/> | The **Start** button starts a job. |
| <InlineImage src="/assets/images/5.1/job-schedule-button-c.png" alt="Schedule button"/> | The **New Schedule** button displays a dropdown with several scheduling options:  * **cron.** Schedule a job based on a Crontab expression. See [Cron Trigger documentation](http://www.quartz-scheduler.org) for more info. * **interval.** Schedule a job to run on an interval after a set starting point. For example, you can schedule a job to run every day at 1:00AM.  Job schedule interval * **job_completion.** Schedule a job to run after another job has completed. You can schedule the job to run if the job succeeds, fails, or regardless of the jobâ€™s success.  Job schedule job_completion |
| <InlineImage src="/assets/images/5.1/job-stop-button-c.png" alt="Stop button"/> | The **Stop** button stops a running job. This results in a status of `"status" : "aborted"`. |
| <InlineImage src="/assets/images/5.1/job-job-history-button-c.png" alt="Job History button"/> | The **Job History** button opens the [Job History panel](#job-history-panel). Click one of the job entries to see additional details. Expand the job details for more information. Click **Open Logs in Dashboard** for complete information. |
| <InlineImage src="/assets/images/5.1/job-clear-datasource-button-c.png" alt="Clear Datasource button"/> | The **Clear Datasource** removes documents from your collection that are indexed from that datasource. The job history will *not* be deleted. |

In the job history panel, there is an icon on each datasource indicating its latest run history. The possible statuses are:

| Icon | Description |
| --- | --- |
| <InlineImage src="/assets/images/5.1/job-history-never-run-icon-c.png" alt="Never Run icon"/> | The job has been created but has not been run. |
| <InlineImage src="/assets/images/5.1/job-running-icon-c.png"alt="Running icon"/> | The job is currently running. Depending on the number of documents being processed, the job can take a long time to complete. Stop the job with the **Stop** button. |
| <InlineImage src="/assets/images/5.1/job-success-icon-c.png"alt="Success icon"/> | The job was completed successfully. |
| <InlineImage src="/assets/images/5.1/job-failed-icon-c.png"alt="Failed icon"/> | The job was not able to successfully run. Expand the job details for more information. Click **Open Logs in Dashboard** for complete information. |
| <InlineImage src="/assets/images/5.1/job-abort-icon-c.png"alt="Aborted icon"/> | The job was manually stopped before it could finish. |

<Frame>![Job history panel](/assets/images/5.1/job-history-all-possible-states.png)</Frame>

<Note>
The image above shows all possible job statuses.
</Note>

## How does the Jobs API work?

In [Checking a job status with the API](#job-status-api) above, two Jobs API endpoints were used to call the datasource `myDatasource`:

* `myApp/jobs?type=datasource` - Retrieves the current datasource job states for *all* datasources of a specified app. In this case, the app is specified as `myApp`.

  You can also use `type=spark` to retrieve all Spark jobs and `type=task` for task jobs.
* `/jobs/datasource:myDatasource/history` - Retrieves a specific objectâ€™s job history. In this case, the object type is a datasource, as selected with `datasource:`.

  Datasources are not the only object type for jobs. There are also Spark jobs (`spark:`) and task jobs (`task:`).

Both of the API calls above send a request to Managed Fusionâ€™s API application, which serves the Jobs API. The API application contains two main components related to job history data, `JobController` and `SolrJobHistoryStore`.

### The Job Controller

The Job Controller is responsible for getting any active jobâ€™s run status, if an active job is running.

In the case of V1 connectors classic datasource jobs, it will reach out to Managed Fusionâ€™s connectors-classic applicationâ€™s connectors API.

When the API application calls the connectors-classic Jobs API, it will first use Zookeeper to identify the IP address of the connector-classic node that is assigned to this datasource, if one exists.

When the connectors-classic node IP assigned to the job is identified, the API application will call out to the connectors-classic node via `http://<connectors-node-ip>:8984/connectors/v1/connectors/jobs/myDatasource`. The call reaches the component `ConnectorsManagerController` to query the job status of currently running jobs with the ID `myDatasource`.