{
  "additionalProperties": true,
  "category": "Other",
  "categoryPriority": 1,
  "description": "Use this job to compute token and phrase level spell correction which you can use in your synonym list.",
  "properties": {
    "analyzerConfigDictionary": {
      "default": "{ \"analyzers\": [ { \"name\": \"LetterTokLowerStem\",\"charFilters\": [ { \"type\": \"htmlstrip\" } ],\"tokenizer\": { \"type\": \"letter\" },\"filters\": [{ \"type\": \"lowercase\" },{ \"type\": \"KStem\" }] }],\"fields\": [{ \"regex\": \".+\", \"analyzer\": \"LetterTokLowerStem\" } ]}",
      "description": "LuceneTextAnalyzer schema for tokenization (JSON-encoded)",
      "hints": [
        "lengthy",
        "code/json"
      ],
      "minLength": 1,
      "title": "Lucene Analyzer Schema for Processing Dictionary",
      "type": "string"
    },
    "analyzerConfigQuery": {
      "default": "{ \"analyzers\": [ { \"name\": \"LetterTokLowerStem\",\"charFilters\": [ { \"type\": \"htmlstrip\" } ],\"tokenizer\": { \"type\": \"letter\" },\"filters\": [{ \"type\": \"lowercase\" },{ \"type\": \"KStem\" }] }],\"fields\": [{ \"regex\": \".+\", \"analyzer\": \"LetterTokLowerStem\" } ]}",
      "description": "LuceneTextAnalyzer schema for tokenization (JSON-encoded)",
      "hints": [
        "lengthy",
        "code/json"
      ],
      "minLength": 1,
      "title": "Lucene Analyzer Schema for Processing Queries",
      "type": "string"
    },
    "corMisRatio": {
      "default": 3,
      "description": "Ratio between correction occurrence count and misspelling occurrence count. Pairs with ratio less than or equal to this number will be filtered. Big number leads to shorter correction list and may have higher quality corrections.",
      "hints": [
        "advanced"
      ],
      "title": "Correction and Misspelling Count Ratio",
      "type": "number"
    },
    "correctCntBoost": {
      "default": 2,
      "description": "When there are multiple possible corrections, we rank corrections based on: editDistBoost / editDist + correctionCountBoost * log(correctionCount) + lastCharMatchBoost * lastCharMatch + soundMatchBoost * soundexMatch. Big number puts more weight on count of correction string occurrences.",
      "hints": [
        "advanced"
      ],
      "title": "Correction Count Boost",
      "type": "number"
    },
    "correctionThreshold": {
      "default": 0.8,
      "description": "The count of occurrence ABOVE which the token/phrases are likely to be corrected spellings. Note that this number can be either fraction (<1.0) to denote a quantile based on count number distribution (shown in the log) or a number (>1.0) to denote the absolute count. A big number may cause performance issues.",
      "hints": [
        "advanced"
      ],
      "title": "Correct Spelling Threshold",
      "type": "number"
    },
    "countField": {
      "default": "count_i",
      "description": "Solr field containing query count",
      "title": "Count Field",
      "type": "string"
    },
    "dataFormat": {
      "default": "solr",
      "description": "Spark-compatible format which training data comes in (like 'solr', 'hdfs', 'file', 'parquet' etc)",
      "enum": [
        "solr",
        "hdfs",
        "file",
        "parquet"
      ],
      "hints": [
        "advanced"
      ],
      "title": "Data format",
      "type": "string"
    },
    "dictionaryCollection": {
      "description": "Solr Collection containing dictionary with correct spellings. E.g., product catalog.",
      "title": "Dictionary Collection",
      "type": "string"
    },
    "dictionaryDataFilterQuery": {
      "default": "*:*",
      "description": "Solr query to use when loading dictionary data",
      "hints": [
        "advanced"
      ],
      "title": "Dictionary Data Filter Query",
      "type": "string"
    },
    "dictionaryField": {
      "description": "Solr field containing dictionary text. Multiple fields can be specified using the format: field1,field2 etc.",
      "title": "Dictionary Field",
      "type": "string"
    },
    "editDistBoost": {
      "default": 2,
      "description": "When there are multiple possible corrections, we rank corrections based on: editDistBoost / editDist + correctionCountBoost * log(correctionCount) + lastCharMatchBoost * lastCharMatch + soundMatchBoost * soundexMatch. Big number puts more weight on shorter edit distance.",
      "hints": [
        "advanced"
      ],
      "title": "Edit Distance Boost",
      "type": "number"
    },
    "enableAutoPublish": {
      "default": false,
      "description": "If true, automatically publishes rewrites for rules. Default is false to allow for initial human-aided reviewing",
      "hints": [
        "advanced"
      ],
      "title": "Enable auto-publishing",
      "type": "boolean"
    },
    "fieldToVectorize": {
      "default": "query",
      "description": "Field containing search strings.",
      "minLength": 1,
      "title": "Input Field",
      "type": "string"
    },
    "filterType": {
      "default": "response",
      "description": "The secondary event type (e.g. response) that can be used for filtering out rare searches.Note: In order to use this `response` default value, please make sure you have type:response in the input collection.If there is no need to filter on number of searches, please leave this parameter blank.",
      "title": "Filtering Event Type",
      "type": "string"
    },
    "id": {
      "description": "The ID for this Spark job. Used in the API to reference this job. Allowed characters: a-z, A-Z, dash (-) and underscore (_). Maximum length: 63 characters.",
      "maxLength": 63,
      "pattern": "[a-zA-Z][_\\-a-zA-Z0-9]*[a-zA-Z0-9]?",
      "title": "Spark Job ID",
      "type": "string"
    },
    "lastCharMatchBoost": {
      "default": 1,
      "description": "When there are multiple possible corrections, we rank corrections based on: editDistBoost / editDist + correctionCountBoost * log(correctionCount) + lastCharMatchBoost * lastCharMatch + soundMatchBoost * soundexMatch. Big number puts more weight on last character match between misspelling and correction strings",
      "hints": [
        "advanced"
      ],
      "title": "Last Character Match Boost",
      "type": "number"
    },
    "lenScale": {
      "default": 5,
      "description": "A scaling factor used to normalize the length of query string to compare against edit distances. The filtering is based on if edit_dist <= string_length/length_scale. A large value for this factor leads to a shorter correction list. A small value leads to a longer correction list but may add lower quality corrections.",
      "hints": [
        "advanced"
      ],
      "title": "Edit Dist vs String Length Scale",
      "type": "integer"
    },
    "mainType": {
      "default": "click",
      "description": "The main signal event type (e.g. click) that the job is based on if input is signal data. E.g., if main type is click, then head and tail tokens/phrases are defined by the number of clicks.",
      "title": "Main Event Type",
      "type": "string"
    },
    "maxDistance": {
      "default": 2,
      "description": "The maximum edit distance between related token/phrases you are interested in. Large number leads to longer correction list but may add lower quality corrections. ",
      "exclusiveMinimum": false,
      "minimum": 1,
      "title": "Maximum Edit Distance",
      "type": "integer"
    },
    "minCountFilter": {
      "default": 10,
      "description": "Minimum number of filtering events (e.g. searches after aggregation) necessary for the query to be considered. The job will only analyze queries that were issued greater or equal to this number of times.",
      "title": "Minimum Filtering Event Count",
      "type": "integer"
    },
    "minCountMain": {
      "default": 1,
      "description": "Minimum number of main events (e.g. clicks after aggregation) necessary for the query to be considered. The job will only analyze queries with clicks greater or equal to this number.",
      "title": "Minimum Main Event Count",
      "type": "integer"
    },
    "minMispellingLen": {
      "default": 5,
      "description": "The minimum length of misspelling to check. Smaller number may lead to problematic corrections. E.g., It is hard to find the right correction for a two or three character string. ",
      "exclusiveMinimum": false,
      "minimum": 1,
      "title": "Minimum Length of Misspelling",
      "type": "integer"
    },
    "minPrefix": {
      "default": 1,
      "description": "The minimum number of matches on starting characters. Note: Setting it to 0 may largely increase running time. ",
      "exclusiveMinimum": false,
      "minimum": 0,
      "title": "Minimum Prefix Match",
      "type": "integer"
    },
    "misspellingThreshold": {
      "default": 0.8,
      "description": "The count of occurrence BELOW which the token/phrases are likely to be misspellings. Note that this number can be either fraction (<1.0) to denote a quantile based on count number distribution (shown in the log) or a number (>1.0) to denote the absolute count.",
      "hints": [
        "advanced"
      ],
      "title": "Misspelling Threshold",
      "type": "number"
    },
    "outputCollection": {
      "description": "Collection to store misspelling and correction pairs. Defaults to the query_rewrite_staging collection for the application.",
      "hints": [
        "dummy"
      ],
      "title": "Output Collection",
      "type": "string"
    },
    "overwriteOutput": {
      "default": true,
      "description": "Overwrite output collection",
      "hints": [
        "hidden",
        "advanced"
      ],
      "title": "Overwrite Output",
      "type": "boolean"
    },
    "randomSeed": {
      "default": 1234,
      "description": "For any deterministic pseudorandom number generation",
      "hints": [
        "advanced"
      ],
      "title": "Random seed",
      "type": "integer"
    },
    "signalDataIndicator": {
      "default": true,
      "description": "The input dataset that the spell checker based on is signal data. If the input data is content document rather than signal, please uncheck.",
      "title": "Input is Signal Data",
      "type": "boolean"
    },
    "signalTypeField": {
      "default": "type",
      "description": "The field name of signal type in the input collection.",
      "hints": [
        "advanced"
      ],
      "title": "Field Name of Signal Type",
      "type": "string"
    },
    "soundMatchBoost": {
      "default": 3,
      "description": "When there are multiple possible corrections, we rank corrections based on: editDistBoost / editDist + correctionCountBoost * log(correctionCount) + lastCharMatchBoost * lastCharMatch + soundMatchBoost * soundexMatch. Big number puts more weight on soundex match between misspelling and correction strings",
      "hints": [
        "advanced"
      ],
      "title": "Sound Match Boost",
      "type": "number"
    },
    "sourceFields": {
      "description": "Solr fields to load (comma-delimited). Leave empty to allow the job to select the required fields to load at runtime.",
      "hints": [
        "hidden"
      ],
      "title": "Fields to Load",
      "type": "string"
    },
    "sparkConfig": {
      "description": "Spark configuration settings.",
      "hints": [
        "advanced"
      ],
      "items": {
        "properties": {
          "key": {
            "title": "Parameter Name",
            "type": "string"
          },
          "value": {
            "title": "Parameter Value",
            "type": "string"
          }
        },
        "required": [
          "key"
        ],
        "type": "object"
      },
      "title": "Spark Settings",
      "type": "array"
    },
    "stopwordsBlobName": {
      "blobType": "file:spark",
      "description": "Name of stopwords blob resource (.txt or .rtf file uploaded to the blob store). This field is marked for deprecation. Going forward, please specify the stopwords blob name as a luceneSchema property.",
      "hints": [
        "advanced"
      ],
      "minLength": 1,
      "reference": "blob",
      "title": "Stopwords blob (Deprecated)",
      "type": "string"
    },
    "stopwordsList": {
      "description": "Stopwords defined in Lucene analyzer config",
      "hints": [
        "readonly",
        "hidden"
      ],
      "items": {
        "blobType": "file:spark",
        "minLength": 1,
        "reference": "blob",
        "type": "string"
      },
      "title": "List of stopwords",
      "type": "array"
    },
    "trainingCollection": {
      "description": "Collection containing search strings and event counts. Should ideally be the signals collection.If an aggregation collection is being used, update the filter query in the advanced options",
      "minLength": 1,
      "title": "Input Collection",
      "type": "string"
    },
    "trainingDataFilterQuery": {
      "default": "type:click OR type:response",
      "description": "Solr query to additionally filter the search strings. Please let it be empty if 'type' field is unavailable in the input collection.",
      "hints": [
        "dummy"
      ],
      "minLength": 3,
      "title": "Data filter query",
      "type": "string"
    },
    "trainingDataFrameConfigOptions": {
      "additionalProperties": {
        "type": "string"
      },
      "description": "Additional spark dataframe loading configuration options",
      "hints": [
        "advanced"
      ],
      "properties": {},
      "title": "Dataframe Config Options",
      "type": "object"
    },
    "trainingDataSamplingFraction": {
      "default": 1,
      "description": "Fraction of the training data to use",
      "exclusiveMaximum": false,
      "hints": [
        "advanced"
      ],
      "maximum": 1,
      "title": "Training data sampling fraction",
      "type": "number"
    },
    "type": {
      "default": "tokenPhraseSpellCorrection",
      "enum": [
        "tokenPhraseSpellCorrection"
      ],
      "hints": [
        "readonly"
      ],
      "title": "Spark Job Type",
      "type": "string"
    },
    "writeOptions": {
      "description": "Options used when writing output to Solr.",
      "hints": [
        "advanced"
      ],
      "items": {
        "properties": {
          "key": {
            "title": "Parameter Name",
            "type": "string"
          },
          "value": {
            "title": "Parameter Value",
            "type": "string"
          }
        },
        "required": [
          "key"
        ],
        "type": "object"
      },
      "title": "Write Options",
      "type": "array"
    }
  },
  "propertyGroups": [
    {
      "label": "Input/Output Parameters",
      "properties": [
        "trainingCollection",
        "outputCollection",
        "dataFormat",
        "trainingDataFilterQuery",
        "writeOptions",
        "trainingDataFrameConfigOptions",
        "trainingDataSamplingFraction",
        "randomSeed",
        "signalDataIndicator"
      ]
    },
    {
      "label": "Field Parameters",
      "properties": [
        "fieldToVectorize",
        "sourceFields",
        "signalTypeField",
        "mainType",
        "filterType",
        "countField"
      ]
    },
    {
      "label": "Boost Parameters",
      "properties": [
        "lastCharMatchBoost",
        "soundMatchBoost",
        "correctCntBoost",
        "editDistBoost"
      ]
    },
    {
      "label": "Model Tuning Parameters",
      "properties": [
        "minCountMain",
        "minCountFilter",
        "correctionThreshold",
        "misspellingThreshold",
        "lenScale",
        "corMisRatio",
        "maxDistance",
        "minMispellingLen",
        "minPrefix"
      ]
    },
    {
      "label": "Featurization Parameters",
      "properties": [
        "analyzerConfigQuery"
      ]
    },
    {
      "label": "Misc. Parameters",
      "properties": [
        "stopwordsBlobName",
        "dictionaryCollection",
        "dictionaryField",
        "dictionaryDataFilterQuery",
        "analyzerConfigDictionary"
      ]
    }
  ],
  "required": [
    "id",
    "trainingCollection",
    "fieldToVectorize",
    "type"
  ],
  "title": "Token and Phrase Spell Correction",
  "type": "object"
}
